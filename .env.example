# Ollama Configuration (optional)
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=llama3.2:3b

# Google Gemini Configuration (optional)
GEMINI_API_KEY=
GEMINI_MODEL=gemini-2.5-flash

# Ollama embedding models
EMBEDDING_MODEL=all-MiniLM-L6-v2  # default
# EMBEDDING_MODEL=embeddinggemma:300m  # 2k context size, 300m parameters
# EMBEDDING_MODEL=mxbai-embed-large  # 512 context size, but larger number of parameters
# EMBEDDING_MODEL=nomic-embed-text  # larger context size of 2k, but smaller model and yields less accurate results
