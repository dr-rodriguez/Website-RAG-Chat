OLLAMA_HOST=http://localhost:11434
QUERY_MODEL=gemma3:12b  # default context size of 128k

# Ollama embedding models
EMBEDDING_MODEL=embeddinggemma:300m  # 2k context size, 300m parameters
# EMBEDDING_MODEL=mxbai-embed-large  # 512 context size, but larger number of parameters
# EMBEDDING_MODEL=nomic-embed-text  # larger context size of 2k, but smaller model and yields less accurate results
